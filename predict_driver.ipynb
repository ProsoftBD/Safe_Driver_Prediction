{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal as signal\n",
    "import pandas as pd\n",
    "import visuals as vs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from spark_sklearn import GridSearchCV\n",
    "\n",
    "random_state = 6\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = 'train.csv'\n",
    "test_file = 'test.csv'\n",
    "submission_file = 'sample_submission.csv'\n",
    "df_train = pd.read_csv(train_file)\n",
    "df_test = pd.read_csv(test_file)\n",
    "submission = pd.read_csv(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_feature = (df_train.shape)[1]\n",
    "\n",
    "X = df_train.drop(['id','target'], axis = 1)\n",
    "Y = df_train['target']\n",
    "X_train, Y_train = shuffle(X, Y, random_state = random_state)\n",
    "\n",
    "# testing data\n",
    "X = df_train.drop(['id','target'], axis = 1)\n",
    "Y = df_train['target']\n",
    "X_test,Y_test = shuffle(X, Y, random_state = random_state)\n",
    "\n",
    "\n",
    "mms = StandardScaler()\n",
    "X_train = mms.fit_transform(X_train)\n",
    "X_test = mms.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import os\n",
    "\n",
    "conf = SparkConf()\n",
    "sc = SparkContext()\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "rfc = RandomForestClassifier(criterion='entropy', random_state = random_state, class_weight='balanced')\n",
    "params = {\n",
    "    'n_estimators': [10, 20, 50, 100],\n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [10, 20, 40, 50]\n",
    "}\n",
    "\n",
    "grid_clf = GridSearchCV(sc, rfc, param_grid = params, scoring = 'accuracy', cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6526a06a449b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# we have to find out best optimized parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_clf' is not defined"
     ]
    }
   ],
   "source": [
    "# we have to find out best optimized parameters\n",
    "grid_clf.fit(X_train, Y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='entropy', max_depth=4, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=6, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_weight = {0:1, 1:2}\n",
    "model = RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
    "            criterion='entropy', max_depth=4, max_features='auto',\n",
    "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
    "            min_samples_leaf=1, min_samples_split=10,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "            oob_score=False, random_state=random_state, verbose=0, warm_start=False)\n",
    "\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(892816, 2)\n",
      "(595212, 2)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Y_pred = model.predict(X_test)\n",
    "test_proba = model.predict_proba(X_test)\n",
    "gb_out = submission\n",
    "print(np.shape(gb_out))\n",
    "print(np.shape(test_proba))\n",
    "sys.exit()\n",
    "gb_out['target'] = test_proba\n",
    "gb_out['target'] = 1-gb_out['target']\n",
    "gb_out.to_csv('gb_predictions1.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('The accuracy of the model is {}'.format(accuracy_score(Y_test, Y_pred)))\n",
    "print('Classification report \\n {}'.format(classification_report(Y_test, Y_pred)))\n",
    "print('Confusion matrix \\n {}'.format(confusion_matrix(Y_pred, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "     assert( len(actual) == len(pred) )\n",
    "     all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "     all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "     totalLosses = all[:,0].sum()\n",
    "     giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    " \n",
    "     giniSum -= (len(actual) + 1) / 2.\n",
    "     return giniSum / len(actual)\n",
    " \n",
    " def gini_normalized(a, p):\n",
    "     return gini(a, p) / gini(a, a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
